# Multi-Agent Research System

An advanced AI-powered code analysis and repository management platform with 90+ comprehensive API endpoints, intelligent agents, and real-time monitoring capabilities.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)](https://github.com/popoloni/multi-agent-researcher)

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/popoloni/multi-agent-researcher.git
cd multi-agent-researcher

# Make scripts executable
chmod +x start_all.sh start_dev.sh start_ui.sh

# Start everything with one command
./start_all.sh

# Or start components individually:
# ./start_dev.sh    # Start backend + Ollama
# ./start_ui.sh     # Start frontend
```

**ğŸ“– For detailed setup instructions, see [SETUP_AND_DEPLOYMENT.md](SETUP_AND_DEPLOYMENT.md)**

### Access the Application
- **Frontend UI**: http://localhost:12001
- **Backend API**: http://localhost:12000
- **API Documentation**: http://localhost:12000/docs

### Managing the System
```bash
# Start all services
./start_all.sh

# Check system status
./start_all.sh status
# or
./check_status.sh

# Stop all services
./start_all.sh stop
# or
./stop_all.sh

# Restart all services
./start_all.sh restart
```

## âœ¨ Key Features

- **ğŸ¤– AI-Powered Documentation** - Professional documentation generation using Ollama LLM with real-time progress tracking
- **ğŸ“Š Hierarchical Code Analysis** - Tree-view functionalities registry with GitHub source code integration  
- **ğŸ” Semantic Search** - Vector-based code search using ChromaDB
- **âš¡ Production Ready** - Extended timeout handling, graceful error recovery, 90+ API endpoints
- **ğŸ—ï¸ Multi-Agent Architecture** - Specialized agents for orchestration, analysis, and dependencies
- **ğŸ¯ Complete Workflow** - GitHub search â†’ clone â†’ index â†’ AI documentation â†’ documentation-aware chat

## ğŸ‰ Latest Improvements (v1.3.0)

### ğŸ’¬ Fully Functional Chat System
- **AI-Powered Conversations**: Working chat interface with Ollama llama3.2:1b integration
- **Repository Context Awareness**: Chat understands repository structure and answers code-specific questions
- **Session Management**: Create and manage chat sessions with unique session IDs
- **Modern UI**: Professional blue theme with enhanced message bubbles and loading animations

### ğŸš€ AI-Powered Documentation Generation
- **Professional Content**: AI-generated descriptions using Ollama llama3.2:1b model
- **Asynchronous Processing**: Background task processing with real-time progress tracking (0-100%)
- **No More Timeouts**: Handles long-running generation (2-3 minutes) gracefully
- **Rich Context**: Generates comprehensive overviews, architecture analysis, and user guides

### ğŸ—‚ï¸ Enhanced Functionalities Registry
- **Hierarchical Structure**: Tree view grouping functions by source files
- **Smart Organization**: Logical sorting (Classes â†’ Functions â†’ Methods â†’ Variables)
- **Functional Buttons**: Eye button opens GitHub source code, doc button navigates to documentation
- **Multiple Views**: Both hierarchical and flat view options

### ğŸ”§ System Stability Improvements
- **Database Architecture**: Fixed async SQLite driver issues and unified database connections
- **Service Integration**: All services now work harmoniously with proper error handling
- **Extended Timeouts**: 5-minute timeout for repository operations (cloning, parsing, AI analysis)
- **Enhanced Error Handling**: User-friendly error messages with automatic clearing

## ğŸ“Š API Overview

| Category | Endpoints | Key Features |
|----------|-----------|--------------|
| **Repository Management** | 25 | GitHub integration, cloning, indexing, analysis |
| **Documentation** | 8 | AI-powered generation, progress tracking, async processing |
| **Chat & RAG** | 6 | AI-powered conversations, session management |
| **Analysis & Quality** | 15 | Code analysis, quality assessment, AI insights |
| **Vector Operations** | 6 | Semantic search, similarity, clustering |
| **Dashboard & Monitoring** | 10 | Real-time metrics, quality dashboards |
| **GitHub Integration** | 10 | Repository search, cloning, branch management |
| **Cache & Analytics** | 6 | Cache management, system metrics |

**Total: 90+ Production-Ready Endpoints**

## ğŸ¯ Use Cases

### For Development Teams
- **AI Documentation Generation** - Automated professional documentation with contextual descriptions
- **Code Quality Assessment** - Automated quality scoring with A+ grade capability
- **Hierarchical Code Navigation** - Tree-view exploration with direct GitHub source links
- **Technical Debt Management** - Identify and prioritize technical debt

### For DevOps & Engineering Managers
- **Real-time Progress Monitoring** - Track documentation generation and repository processing
- **Batch Processing** - Analyze multiple repositories efficiently with extended timeout handling
- **Quality Dashboards** - Visual metrics and team insights
- **Production Deployment** - Docker, Kubernetes, cloud-ready architecture

## ğŸ”§ Configuration

### Basic Setup
```bash
# Optional: Enhanced caching with Redis
REDIS_URL=redis://localhost:6379

# Optional: AI model configuration
OLLAMA_BASE_URL=http://localhost:11434

# GitHub integration
GITHUB_TOKEN=your_github_token_here
```

### ğŸ¤– AI Model Configuration

The system supports multiple AI providers (Anthropic Claude and Ollama) with flexible model selection for different components:

#### **Environment Variables**
```bash
# === ANTHROPIC CONFIGURATION ===
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# === RESEARCH AGENTS ===
LEAD_AGENT_MODEL=claude-4-sonnet-20241120          # Lead research planning
SUBAGENT_MODEL=claude-4-sonnet-20241120            # Sub-research execution
CITATION_MODEL=claude-3-5-haiku-20241022           # Citation generation

# === KENOBI CHAT & CODE ANALYSIS ===
KENOBI_MODEL=claude-4-sonnet-20241120              # Code analysis & chat

# === DOCUMENTATION GENERATION ===
DOCUMENTATION_MODEL=claude-4-sonnet-20241120       # Documentation generation

# === GOOGLE SEARCH (for research) ===
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_CSE_ID=your_cse_id_here
```

#### **Available Models**

**Anthropic Claude Models:**
- `claude-4-opus-20241120` - Highest performance, most expensive
- `claude-4-sonnet-20241120` - Balanced performance/cost (recommended)
- `claude-3-5-sonnet-20241022` - Good performance, lower cost
- `claude-3-5-haiku-20241022` - Fast, cost-effective for simple tasks

**Ollama Local Models:**
- `llama3.1:70b` - Highest quality (requires 40GB RAM)
- `llama3.1:8b` - Good balance (requires 8GB RAM)
- `mistral:7b` - Efficient alternative
- `llama3.2:3b` - Lightweight option
- `llama3.2:1b` - Ultra-lightweight (default)

#### **Model Configuration Examples**

**High-Performance Setup (Best Quality)**
```bash
LEAD_AGENT_MODEL=claude-4-opus-20241120
SUBAGENT_MODEL=claude-4-sonnet-20241120
CITATION_MODEL=claude-3-5-haiku-20241022
KENOBI_MODEL=claude-4-sonnet-20241120
DOCUMENTATION_MODEL=claude-4-sonnet-20241120
```

**Balanced Setup (Recommended)**
```bash
LEAD_AGENT_MODEL=claude-4-sonnet-20241120
SUBAGENT_MODEL=claude-4-sonnet-20241120
CITATION_MODEL=claude-3-5-haiku-20241022
KENOBI_MODEL=claude-3-5-sonnet-20241022
DOCUMENTATION_MODEL=claude-3-5-sonnet-20241022
```

**Local-Only Setup (No API Costs)**
```bash
LEAD_AGENT_MODEL=llama3.1:8b
SUBAGENT_MODEL=mistral:7b
CITATION_MODEL=llama3.2:3b
KENOBI_MODEL=llama3.1:8b
DOCUMENTATION_MODEL=llama3.1:8b
```

**Hybrid Setup (Best of Both)**
```bash
LEAD_AGENT_MODEL=claude-4-sonnet-20241120
SUBAGENT_MODEL=llama3.1:8b
CITATION_MODEL=llama3.2:3b
KENOBI_MODEL=claude-4-sonnet-20241120
DOCUMENTATION_MODEL=claude-3-5-sonnet-20241022
```

#### **How to Change Models**
1. Edit your `.env` file with your preferred models
2. Restart the backend: `./start_all.sh restart`
3. Test the changes by running research or chat

> **ğŸ’¡ Tip**: Start with the **Balanced Setup** and adjust based on your quality requirements and budget.

### Production Deployment
```yaml
# docker-compose.yml
version: '3.8'
services:
  app:
    build: .
    ports: ["12000:12000"]
    environment:
      - REDIS_URL=redis://redis:6379
      - GITHUB_TOKEN=${GITHUB_TOKEN}
    depends_on: [redis, ollama]
  frontend:
    build: ./frontend
    ports: ["12001:3000"]
  redis:
    image: redis:alpine
  ollama:
    image: ollama/ollama
    volumes:
      - ollama_data:/root/.ollama
```

## ğŸ“± Web Interface

- **[Interactive API Docs](http://localhost:12000/docs)** - Swagger UI with all 90+ endpoints
- **[Frontend Dashboard](http://localhost:12001)** - Complete UI with AI documentation generation
- **[Repository Management](http://localhost:12001/repositories)** - Clone, analyze, and manage repositories
- **[Kenobi Chat](http://localhost:12001/chat)** - AI-powered chat about your codebase
- **[Functionalities Registry](http://localhost:12001/repositories/{id}/functionalities)** - Hierarchical code exploration
- **[Documentation Viewer](http://localhost:12001/repositories/{id}/documentation)** - AI-generated documentation

## ğŸ“ Project Structure

```
multi-agent-researcher/
â”œâ”€â”€ app/                          # Backend FastAPI application
â”‚   â”œâ”€â”€ api/                      # API endpoints and routers
â”‚   â”œâ”€â”€ core/                     # Core business logic and services
â”‚   â”œâ”€â”€ models/                   # Database models and schemas
â”‚   â””â”€â”€ utils/                    # Utility functions and helpers
â”œâ”€â”€ frontend/                     # React frontend application
â”‚   â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ public/                   # Static assets
â”‚   â””â”€â”€ build/                    # Production build output
â”œâ”€â”€ docs/                         # Comprehensive documentation
â”‚   â”œâ”€â”€ api/                      # API documentation and examples
â”‚   â”œâ”€â”€ guides/                   # User guides and tutorials
â”‚   â”œâ”€â”€ architecture/             # System architecture documentation
â”‚   â””â”€â”€ reports/                  # Implementation reports and metrics
â”œâ”€â”€ migration_scripts/            # Database migration and data scripts
â”‚   â”œâ”€â”€ database/                 # Database schema migrations
â”‚   â”œâ”€â”€ data/                     # Data import/export scripts
â”‚   â””â”€â”€ legacy/                   # Legacy system migration tools
â”œâ”€â”€ demo/                         # Demo scripts and examples
â”œâ”€â”€ scripts/                      # Utility and automation scripts
â”œâ”€â”€ *.sh                         # Startup and management scripts
â”œâ”€â”€ cleanup.sh                   # Repository cleanup script
â”œâ”€â”€ cleanup_dev_env.sh           # Development environment cleanup
â””â”€â”€ requirements.txt             # Python dependencies
```

## ğŸ“š Documentation

### ğŸš€ [Quick Start Guide](docs/guides/quick-start.md)
Get up and running in 5 minutes with step-by-step instructions.

### ğŸ“– [Complete Documentation](docs/README.md)
Comprehensive documentation including:
- **[API Reference](docs/api/README.md)** - All 90+ endpoints with examples
- **[User Guides](docs/guides/README.md)** - Feature guides and tutorials  
- **[Architecture](docs/architecture/README.md)** - System design and components
- **[Deployment Guide](docs/guides/deployment.md)** - Production deployment
- **[Implementation Reports](docs/reports/README.md)** - Development phases and metrics
- **[Migration Scripts](migration_scripts/README.md)** - Database and data migration tools

### ğŸ“‹ [Changelog](CHANGELOG.md)
See [CHANGELOG.md](CHANGELOG.md) for detailed information about recent improvements and bug fixes.

## ğŸ† System Metrics

- **Development Time**: 4 weeks, 4 phases + debugging session improvements
- **Code Quality**: 85% complete with high-quality foundations
- **Performance**: Extended timeout handling, real-time progress tracking
- **Functionality**: 90+ endpoints, AI-powered documentation, hierarchical navigation
- **Architecture**: Multi-agent system with graceful error handling

## ğŸ§ª Testing

### Verified Working Features
- âœ… **Chat System**: AI-powered conversations with repository context awareness
- âœ… **GitHub Integration**: Complete API with search, cloning, repository info
- âœ… **AI Documentation**: Professional content generation with Ollama integration
- âœ… **Repository Processing**: 5-minute timeout handling for complex repositories
- âœ… **Functionalities Registry**: Hierarchical navigation with GitHub source links
- âœ… **Database Operations**: Async SQLite with proper service integration
- âœ… **Progress Tracking**: Real-time updates for long-running operations
- âœ… **Error Handling**: User-friendly messages with automatic recovery

### Test Coverage
```bash
# Run comprehensive tests
./verify_application.sh

# Test specific workflows
python demo/demo_working_features.py
python demo/add_repository.py
python demo/demo_documentation_generation.py
```

## ğŸ¤ Contributing

See our [Contributing Guide](docs/guides/contributing.md) for development setup and contribution workflow.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

**[ğŸ“š Full Documentation](docs/README.md)** | **[ğŸš€ Quick Start](docs/guides/quick-start.md)** | **[ğŸ“Š API Reference](docs/api/README.md)** | **[ğŸ—ï¸ Architecture](docs/architecture/README.md)** | **[ğŸ“‹ Changelog](CHANGELOG.md)**