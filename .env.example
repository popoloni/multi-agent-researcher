# Anthropic API Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration (optional - for local models)
OLLAMA_HOST=http://localhost:11434

# Redis Configuration (optional - uses in-memory store if not provided)
REDIS_URL=redis://localhost:6379

# Model Configuration (optional - supports both Anthropic and Ollama models)
# Available Anthropic models:
# Claude 4 Series: claude-4-opus-20241120, claude-4-sonnet-20241120
# Claude 3.5 Series: claude-3-5-sonnet-20241022, claude-3-5-sonnet-20240620, claude-3-5-haiku-20241022  
# Claude 3 Series: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307

# Available Ollama models (requires Ollama installation):
# llama3.1:8b, llama3.1:70b, llama3.2:3b, mistral:7b, mixtral:8x7b, qwen2.5:7b, gemma2:9b, phi3:3.8b

# Recommended configurations:
# Anthropic High Performance (best quality, highest cost):
# LEAD_AGENT_MODEL=claude-4-opus-20241120
# SUBAGENT_MODEL=claude-4-sonnet-20241120
# CITATION_MODEL=claude-3-5-haiku-20241022

# Anthropic Balanced (default - good quality, moderate cost):
# LEAD_AGENT_MODEL=claude-4-sonnet-20241120
# SUBAGENT_MODEL=claude-4-sonnet-20241120
# CITATION_MODEL=claude-3-5-haiku-20241022

# Ollama High Performance (local, no API costs):
# LEAD_AGENT_MODEL=llama3.1:70b
# SUBAGENT_MODEL=llama3.1:8b
# CITATION_MODEL=llama3.2:3b

# Ollama Balanced (local, moderate resource usage):
# LEAD_AGENT_MODEL=llama3.1:8b
# SUBAGENT_MODEL=mistral:7b
# CITATION_MODEL=llama3.2:3b

# Mixed Optimal (Claude for lead, Ollama for subagents):
# LEAD_AGENT_MODEL=claude-4-sonnet-20241120
# SUBAGENT_MODEL=llama3.1:8b
# CITATION_MODEL=llama3.2:3b

# Search API Configuration (optional - uses mock search if not provided)
# GOOGLE_SEARCH_API_KEY=your_google_search_api_key
# GOOGLE_SEARCH_ENGINE_ID=your_search_engine_id
# BING_SEARCH_API_KEY=your_bing_search_api_key